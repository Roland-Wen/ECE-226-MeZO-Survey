{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c71f41f-ca2f-4e56-a985-b4d300786a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcff922d-ac2f-4c99-8b64-542de4afaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zo_opt_file = \"ZO_opt.csv\"\n",
    "hybrid_file = \"Hybrid.csv\"\n",
    "peft_file = \"PEFT.csv\"\n",
    "mem_file = \"Mem_usage.csv\"\n",
    "\n",
    "zo_opt_df = pd.read_csv(zo_opt_file).dropna(how='all')\n",
    "hybrid_df = pd.read_csv(hybrid_file).dropna(how='all')\n",
    "peft_df = pd.read_csv(peft_file).dropna(how='all')\n",
    "mem_df = pd.read_csv(mem_file).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e974a8f-f5ef-4a6a-8500-5f870f2755e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_MODELS = (\"RoBERTa-Base\", \"RoBERTa-large\", \"RoBERTa-large \")\n",
    "MEDIUM_MODELS = (\"OPT-1.3B\", \"OPT-2.7B\")\n",
    "LARGE_MODELS = (\"LLaMA-7b\", \"LLaMA2-7b\", \"LlaMA3-8b\", \"OPT-13B\")\n",
    "\n",
    "TASK_TYPE_TO_DATASET = {\"Natural Language Inference\": (\"SNLI\", \"MNLI\", \"RTE\", \"CB\"),\n",
    "                        \"Sentiment Analysis\": (\"SST-2\", \"SST-5\"),\n",
    "                        \"Reading Comprehension/Question Answering\": (\"SQuAD\", \"MultiRC\", \"ReCoRD\", \"DROP\", \"BoolQ\"),\n",
    "                        \"Commonsense & Causal Reasoning\": (\"COPA\", \"WSC\"),\n",
    "                        \"Word Sense/Contextual Meaning\": (\"WIC\"),\n",
    "                        \"Question Classification\": (\"TREC\")}\n",
    "\n",
    "def get_dataset_type(dataset_name):\n",
    "    for task_type, datasets in TASK_TYPE_TO_DATASET.items():\n",
    "        if dataset_name in datasets:\n",
    "            return task_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "def get_model_size(model_name):\n",
    "    if model_name in SMALL_MODELS:\n",
    "        return \"small\"\n",
    "    elif model_name in MEDIUM_MODELS:\n",
    "        return \"medium\"\n",
    "    elif model_name in LARGE_MODELS:\n",
    "        return \"large\"\n",
    "    else:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed01da-60ae-4fc1-b5ca-ed2a2aa07ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "zo_opt_df['method_type'] = 'zo_opt'\n",
    "hybrid_df['method_type'] = 'hybrid'\n",
    "peft_df['method_type'] = 'peft'\n",
    "\n",
    "combined_df = pd.concat([zo_opt_df, hybrid_df, peft_df], ignore_index=True)\n",
    "combined_df['model_type'] = combined_df['Model'].apply(get_model_size)\n",
    "combined_df = combined_df.map(lambda x: x * 100 if isinstance(x, (int, float)) and x < 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6644d39-96cb-4bea-b390-17ef6dc5aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(combined_df, fix_elements, threshold=5):\n",
    "    \"\"\"\n",
    "    Interpolate missing performance values by averaging available data while fixing certain elements.\n",
    "        method A (with category A') \n",
    "        fine-tuning model B (with model size B')\n",
    "        on dataset C (with task type C')\n",
    "    Fix some of subset of {A, A', B, B', C, C'} and take the avg\n",
    "    If not enough data for a criteria (eg A), fix its ' (eg A') instead\n",
    "    eg. Interpolating (x): HiZOO fine-tuning llama2-7b on the SST-2 dataset\n",
    "        fix_elements = (\"A\", \"B'\", \"C'\")\n",
    "        x = mean(HiZOO fine-tuning large model on sentiment analysis dataset)\n",
    "    \n",
    "    Parameters:\n",
    "    - combined_df (pd.DataFrame): Merged DataFrame containing all method types.\n",
    "    - fix_elements (tuple): Elements to fix during interpolation.\n",
    "    - threshold (int, optional): Minimum number of available data points required to refine filtering. Default is 5.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with interpolated missing values.\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(zo_opt_df, pd.DataFrame) and isinstance(hybrid_df, pd.DataFrame) and isinstance(peft_df, pd.DataFrame)\n",
    "    assert isinstance(fix_elements, list) and len(fix_elements) <= 6\n",
    "    assert all([element in (\"A\", \"A'\", \"B\", \"B'\", \"C\", \"C'\") for element in fix_elements])\n",
    "\n",
    "    new_df = combined_df.copy()\n",
    "    for i, row in combined_df.iterrows():\n",
    "        method, model = row.iloc[0], row.iloc[1]\n",
    "        method_type = row['method_type']\n",
    "        model_type = get_model_size(model)\n",
    "\n",
    "        for j, entry in enumerate(row[2:]):\n",
    "            if isinstance(entry, str) or not np.isnan(entry):\n",
    "                continue\n",
    "\n",
    "            dataset_name = combined_df.columns[j+2]\n",
    "            dataset_type = get_dataset_type(dataset_name)\n",
    "            sample_df = combined_df\n",
    "\n",
    "            # filter by general category\n",
    "            if \"A'\" in fix_elements:\n",
    "                sample_df_experiment = sample_df[sample_df['method_type'] == method_type]\n",
    "            if \"B'\" in fix_elements:\n",
    "                sample_df = sample_df[sample_df['model_type'] == model_type]\n",
    "            if \"C'\" in fix_elements:\n",
    "                good_columns = [get_dataset_type(col) == dataset_type \n",
    "                                for col in combined_df.columns]\n",
    "                good_columns[0] = True\n",
    "                good_columns[1] = True\n",
    "                sample_df = sample_df.iloc[:, good_columns]\n",
    "            \n",
    "            # filter by specific if possible\n",
    "            if \"A\" in fix_elements:\n",
    "                sample_df_experiment = sample_df[sample_df['method'] == method]\n",
    "                if sample_df.iloc[:, 2:].apply(lambda row: row.notna().sum(), axis=1).sum() >= threshold:\n",
    "                    sample_df = sample_df_experiment\n",
    "            if \"B\" in fix_elements:\n",
    "                sample_df_experiment = sample_df[sample_df['model'] == model]\n",
    "                if sample_df.iloc[:, 2:].apply(lambda row: row.notna().sum(), axis=1).sum() >= threshold:\n",
    "                    sample_df = sample_df_experiment\n",
    "            if \"C\" in fix_elements:\n",
    "                sample_df_experiment = sample_df.loc[:, (\"Method\", \"Model\", dataset_name)]\n",
    "                if sample_df.iloc[:, 2:].apply(lambda row: row.notna().sum(), axis=1).sum() >= threshold:\n",
    "                    sample_df = sample_df_experiment\n",
    "\n",
    "            # calculate\n",
    "            new_df.iloc[i, j+2] = sample_df.iloc[:, 2:].apply(pd.to_numeric, errors='coerce').mean(skipna=True).mean(skipna=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e009e-bde8-48c7-a80a-9af1700b53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_df = interpolate(combined_df, [\"A'\", \"B'\", \"C'\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22464c13-a9c6-40ee-a5fd-0f6bde5505b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.isna().sum().sum())\n",
    "print(q1_df.isna().sum().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
