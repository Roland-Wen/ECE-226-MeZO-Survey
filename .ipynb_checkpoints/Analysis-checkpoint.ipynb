{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c71f41f-ca2f-4e56-a985-b4d300786a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcff922d-ac2f-4c99-8b64-542de4afaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zo_opt_file = \"ZO_opt.csv\"\n",
    "hybrid_file = \"Hybrid.csv\"\n",
    "peft_file = \"PEFT.csv\"\n",
    "mem_file = \"Mem_usage.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83b696c2-163f-4067-afa4-02189430984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zo_opt_df = pd.read_csv(zo_opt_file).dropna(how='all')\n",
    "hybrid_df = pd.read_csv(hybrid_file).dropna(how='all')\n",
    "peft_df = pd.read_csv(peft_file).dropna(how='all')\n",
    "mem_df = pd.read_csv(mem_file).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e974a8f-f5ef-4a6a-8500-5f870f2755e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_MODELS = (\"RoBERTa-Base\", \"RoBERTa-large\", \"RoBERTa-large \")\n",
    "MEDIUM_MODELS = (\"OPT-1.3B\", \"OPT-2.7B\")\n",
    "LARGE_MODELS = (\"LLaMA-7b\", \"LLaMA2-7b\", \"LlaMA3-8b\", \"OPT-13B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09be4e53-e71b-4762-a798-2d12ade7fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPE_TO_DATASET = {\"Natural Language Inference\": (\"SNLI\", \"MNLI\", \"RTE\", \"CB\"),\n",
    "                        \"Sentiment Analysis\": (\"SST-2\", \"SST-5\"),\n",
    "                        \"Reading Comprehension/Question Answering\": (\"SQuAD\", \"MultiRC\", \"ReCoRD\", \"DROP\", \"BoolQ\"),\n",
    "                        \"Commonsense & Causal Reasoning\": (\"COPA\", \"WSC\"),\n",
    "                        \"Word Sense/Contextual Meaning\": (\"WIC\"),\n",
    "                        \"Question Classification\": (\"TREC\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e574e1e5-e215-405a-9f63-b10438816fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hybrid': squad      0\n",
      "multirc    0\n",
      "record     0\n",
      "drop       0\n",
      "dtype: int64, 'PEFT': squad      0\n",
      "multirc    0\n",
      "record     0\n",
      "drop       0\n",
      "dtype: int64, 'ZO_opt': squad      0\n",
      "multirc    0\n",
      "record     0\n",
      "drop       0\n",
      "dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "def clean_dataframe(df):\n",
    "    \"\"\"\n",
    "    Interpolates missing values in a DataFrame.\n",
    "    Assumes that numerical columns can be interpolated.\n",
    "    \"\"\"\n",
    "    # First, fill any leading/trailing NaNs if needed.\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    # Then, interpolate internal NaNs.\n",
    "    df = df.interpolate()\n",
    "    return df\n",
    "\n",
    "def get_model_size(model_name):\n",
    "    \"\"\"\n",
    "    Returns the model size category for a given model name.\n",
    "    \"\"\"\n",
    "    # Remove any extra whitespace for consistency\n",
    "    model_name = model_name.strip()\n",
    "    if model_name in SMALL_MODELS:\n",
    "        return 'Small'\n",
    "    elif model_name in MEDIUM_MODELS:\n",
    "        return 'Medium'\n",
    "    elif model_name in LARGE_MODELS:\n",
    "        return 'Large'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def aggregate_results(perf_dfs, mem_df):\n",
    "    \"\"\"\n",
    "    Aggregates performance and memory usage data.\n",
    "    \n",
    "    Args:\n",
    "      perf_dfs (list): List of DataFrames containing performance metrics.\n",
    "      mem_df (DataFrame): DataFrame containing memory usage data.\n",
    "    \n",
    "    Returns:\n",
    "      aggregated (DataFrame): A DataFrame with each model's average performance and memory usage.\n",
    "    \"\"\"\n",
    "    # Clean all dataframes\n",
    "    perf_dfs = [clean_dataframe(df) for df in perf_dfs]\n",
    "    mem_df = clean_dataframe(mem_df)\n",
    "    \n",
    "    # Assume each performance df has a 'Model' and a 'Performance' column.\n",
    "    # First, we merge the performance dfs by 'Model'\n",
    "    merged_perf = perf_dfs[0]\n",
    "    for df in perf_dfs[1:]:\n",
    "        merged_perf = pd.merge(merged_perf, df, on='Model', how='outer', suffixes=('', '_dup'))\n",
    "    \n",
    "    # If there are duplicate performance columns, average them.\n",
    "    # For demonstration, we assume that after merge, columns with similar names can be averaged.\n",
    "    # Here we simply take the mean across numeric columns (ignoring the 'Model' column).\n",
    "    performance_cols = merged_perf.select_dtypes(include=[np.number]).columns\n",
    "    merged_perf['Avg_Performance'] = merged_perf[performance_cols].mean(axis=1)\n",
    "    \n",
    "    # Merge the performance data with memory usage data on 'Model'\n",
    "    aggregated = pd.merge(merged_perf[['Model', 'Avg_Performance']], mem_df, on='Model', how='outer')\n",
    "    # Assume memory usage is in a column called 'Memory'\n",
    "    # If there are duplicates or extra columns, adjust as needed.\n",
    "    \n",
    "    # Add model size classification\n",
    "    aggregated['Model_Size'] = aggregated['Model'].apply(get_model_size)\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "def analyze_model_sizes(aggregated):\n",
    "    \"\"\"\n",
    "    Analyzes aggregated results by grouping by model size and visualizing performance and memory usage.\n",
    "    \n",
    "    Args:\n",
    "      aggregated (DataFrame): DataFrame with columns ['Model', 'Avg_Performance', 'Memory', 'Model_Size'].\n",
    "    \n",
    "    Returns:\n",
    "      None: Displays plots.\n",
    "    \"\"\"\n",
    "    # Group by Model_Size\n",
    "    grouped = aggregated.groupby('Model_Size').agg({\n",
    "        'Avg_Performance': 'mean',\n",
    "        'Memory': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(\"Aggregated averages by model size:\")\n",
    "    print(grouped)\n",
    "    \n",
    "    # Visualization: bar chart for average performance by model size\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x='Model_Size', y='Avg_Performance', data=aggregated, ci='sd')\n",
    "    plt.title(\"Average Performance by Model Size\")\n",
    "    plt.xlabel(\"Model Size\")\n",
    "    plt.ylabel(\"Average Performance\")\n",
    "    \n",
    "    # Visualization: bar chart for average memory usage by model size\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x='Model_Size', y='Memory', data=aggregated, ci='sd')\n",
    "    plt.title(\"Average Memory Usage by Model Size\")\n",
    "    plt.xlabel(\"Model Size\")\n",
    "    plt.ylabel(\"Memory Usage\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run analysis\n",
    "\n",
    "# List of performance DataFrames\n",
    "performance_dfs = [zo_opt_df, hybrid_df, peft_df]\n",
    "\n",
    "# Aggregate results (this assumes each CSV has a 'Model' column and at least one numeric column for performance and memory usage)\n",
    "aggregated_results = aggregate_results(performance_dfs, mem_df)\n",
    "\n",
    "# Visualize and analyze the results\n",
    "analyze_model_sizes(aggregated_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19ae60-3514-4d73-baf9-92c7a0550f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
